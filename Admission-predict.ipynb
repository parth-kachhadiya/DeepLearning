{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6a0b44f6-b3ab-446d-b251-ad8235580bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8a0e678a-a883-4e47-803c-3da84c876ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e08b5dbb-5c64-42e8-9f84-e16661b32aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "03cdb94a-ab15-47e9-a7c6-e307086bd097",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../Own_model/data_csv/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f29a959d-ed44-482c-9a93-42f9215bb935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>496</td>\n",
       "      <td>332</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>497</td>\n",
       "      <td>337</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>498</td>\n",
       "      <td>330</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>499</td>\n",
       "      <td>312</td>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>500</td>\n",
       "      <td>327</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0             1        337          118                  4  4.5   4.5  9.65   \n",
       "1             2        324          107                  4  4.0   4.5  8.87   \n",
       "2             3        316          104                  3  3.0   3.5  8.00   \n",
       "3             4        322          110                  3  3.5   2.5  8.67   \n",
       "4             5        314          103                  2  2.0   3.0  8.21   \n",
       "..          ...        ...          ...                ...  ...   ...   ...   \n",
       "495         496        332          108                  5  4.5   4.0  9.02   \n",
       "496         497        337          117                  5  5.0   5.0  9.87   \n",
       "497         498        330          120                  5  4.5   5.0  9.56   \n",
       "498         499        312          103                  4  4.0   5.0  8.43   \n",
       "499         500        327          113                  4  4.5   4.5  9.04   \n",
       "\n",
       "     Research  Chance of Admit   \n",
       "0           1              0.92  \n",
       "1           1              0.76  \n",
       "2           1              0.72  \n",
       "3           1              0.80  \n",
       "4           0              0.65  \n",
       "..        ...               ...  \n",
       "495         1              0.87  \n",
       "496         1              0.96  \n",
       "497         1              0.93  \n",
       "498         0              0.73  \n",
       "499         0              0.84  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "59ce807f-214d-4efb-a154-5fe6dddbfb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4df06683-5e3b-4984-81c3-eb24e77a1da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "783b38c8-4522-4c22-8142-7cf99f9b1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Serial No.', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54fa40e6-e8a2-4d93-b943-e93d886ca10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0fbd20d2-68be-4e2f-8c57-b8fc155a3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1f96f530-76f3-42d8-931f-1b69f0849182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 7)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "74cd297e-c488-41c6-9434-477b66f9c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3e813466-0dc3-4492-8ae6-dcb621cca3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n",
       "        0.        ],\n",
       "       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n",
       "        1.        ],\n",
       "       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n",
       "        1.        ],\n",
       "       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n",
       "        1.        ],\n",
       "       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7329a087-e11d-4515-8366-6121ddc60df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(7, activation='relu', input_dim=7))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "932d88e1-3e11-4a3b-b92c-70fb77a52dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │              \u001b[38;5;34m80\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> (588.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m147\u001b[0m (588.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> (588.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m147\u001b[0m (588.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ce685482-b2f8-47b2-9ae8-769167d145ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "032e3f90-9007-4d84-82c6-78a7cf729be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.5792 - val_loss: 0.4452\n",
      "Epoch 2/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3815 - val_loss: 0.2814\n",
      "Epoch 3/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2452 - val_loss: 0.1566\n",
      "Epoch 4/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1266 - val_loss: 0.0736\n",
      "Epoch 5/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0641 - val_loss: 0.0296\n",
      "Epoch 6/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0254 - val_loss: 0.0160\n",
      "Epoch 7/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0139 - val_loss: 0.0152\n",
      "Epoch 8/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0129 - val_loss: 0.0149\n",
      "Epoch 9/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0138 - val_loss: 0.0135\n",
      "Epoch 10/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0121 - val_loss: 0.0123\n",
      "Epoch 11/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 12/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0099 - val_loss: 0.0111\n",
      "Epoch 13/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0092 - val_loss: 0.0108\n",
      "Epoch 14/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 15/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092 - val_loss: 0.0101\n",
      "Epoch 16/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 17/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0076 - val_loss: 0.0095\n",
      "Epoch 18/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0093 - val_loss: 0.0092\n",
      "Epoch 19/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 20/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - val_loss: 0.0087\n",
      "Epoch 21/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 22/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 23/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0072 - val_loss: 0.0081\n",
      "Epoch 24/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 25/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 26/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 27/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 28/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 29/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - val_loss: 0.0069\n",
      "Epoch 30/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 31/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0056 - val_loss: 0.0066\n",
      "Epoch 32/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 33/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0061 - val_loss: 0.0063\n",
      "Epoch 34/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 35/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 36/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 37/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 38/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 39/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 40/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 41/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0048 - val_loss: 0.0052\n",
      "Epoch 42/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0051\n",
      "Epoch 43/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 44/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 45/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 46/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 47/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 48/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 49/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Epoch 50/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 51/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 52/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 53/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 54/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 55/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 56/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 57/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 58/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0041 - val_loss: 0.0042\n",
      "Epoch 59/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 60/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 61/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 62/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 63/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 64/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 65/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 66/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 67/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 68/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 69/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 70/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 71/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 72/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 73/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 74/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 75/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 76/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 77/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 78/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 79/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 80/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 81/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 82/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 83/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 84/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 85/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 86/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 87/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 88/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 89/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 90/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 91/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 92/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 93/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 94/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 95/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 96/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 97/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 98/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 99/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 100/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 101/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 102/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 103/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 104/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 105/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 106/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 107/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 108/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 109/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 110/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 111/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 112/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 113/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 114/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 115/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 116/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 117/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 118/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 119/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 120/120\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - val_loss: 0.0035\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=120, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "99d47d3f-34d9-4930-bb98-ca16635c56c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0193b766-8638-4de9-a471-6402a4f4b0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8120952213955541"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5ba79ae4-6c26-4bee-a4e0-9513393ddf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
