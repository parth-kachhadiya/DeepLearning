{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4297c8-d1f8-47fc-8445-6220c577d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "501c14fa-e03f-4406-bfb4-a606811c6d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[8, 8, 1], [7, 9, 1], [6, 10, 0], [5, 5, 0]], columns=['cgpa', 'profile_score', 'placed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b2fd274-d4c8-4da9-ae18-0cd862164829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>profile_score</th>\n",
       "      <th>placed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  profile_score  placed\n",
       "0     8              8       1\n",
       "1     7              9       1\n",
       "2     6             10       0\n",
       "3     5              5       0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1c00312-da83-4f89-88e1-8a3cc2fc8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_params(layer_dim):\n",
    "    np.random.seed(3)  \n",
    "    parameters = {}\n",
    "    L = len(layer_dim)\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.ones((layer_dim[l-1], layer_dim[l])) * 0.1\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dim[l], 1))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ad6aa1e-f62b-43d7-b14b-234041ef07e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    A = 1 / (1 + np.exp(-z))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "080ea40f-1b49-42ea-9231-97e4892a836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate output of any given neuron\n",
    "def forward(A, W, b):\n",
    "    Z = np.dot(W.T, A) + b\n",
    "    A = sigmoid(Z)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b6f2fbe-c9f4-4eb3-8eb2-328265aab5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, params):\n",
    "    A = X\n",
    "    L = len(params) // 2\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        A_prev = A\n",
    "        Wl = params['W' + str(l)]\n",
    "        bl = params['b' + str(l)]\n",
    "\n",
    "        print(f\"A{str(l-1)} : {A_prev}\")\n",
    "        print(f\"W{str(l)} : {Wl}\")\n",
    "        print(f\"b{str(l)} : {bl}\")\n",
    "        print(\"--\" * 25)\n",
    "\n",
    "        A = forward(A_prev, Wl, bl)\n",
    "        print(f\"A{str(l)} : {A}\")\n",
    "        print(\"**\" * 25)\n",
    "\n",
    "    return A, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f7115f24-ea0d-4f29-9672-5811f70e7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, Y, y_hat, A1, X):\n",
    "    params['W2'][0][0] = params['W2'][0][0] + (0.02 * (Y - y_hat) * A1[0][0])\n",
    "    params['W2'][1][0] = params['W2'][1][0] + (0.02 * (Y - y_hat) * A1[1][0])\n",
    "    params['b2'][0][0] = params['W2'][1][0] + (0.02 * (Y - y_hat))\n",
    "\n",
    "    params['W1'][0][0] = params['W1'][0][0] + (0.02 * (Y - y_hat) * params['W2'][0][0] * A1[0][0] * (1 - A1[0][0]) * X[0][0])\n",
    "    params['W1'][0][0] = params['W1'][0][1] + (0.02 * (Y - y_hat) * params['W2'][0][0] * A1[0][0] * (1 - A1[0][0]) * X[1][0])\n",
    "    params['b1'][0][0] = params['b1'][0][0] + (0.02 * (Y - y_hat) * params['W2'][0][0] * A1[0][0] * (1 - A1[0][0]))\n",
    "\n",
    "    params['W1'][1][0] = params['W1'][1][0] + (0.02 * (Y - y_hat) * params['W2'][1][0] * A1[1][0] * (1 - A1[1][0]) * X[0][0])\n",
    "    params['W1'][1][1] = params['W1'][1][1] + (0.02 * (Y - y_hat) * params['W2'][1][0] * A1[1][0] * (1 - A1[1][0]) * X[1][0])\n",
    "    params['b1'][1][0] = params['b1'][1][0] + (0.02 * (Y - y_hat) * params['W2'][1][0] * A1[1][0] * (1 - A1[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf5704-e92f-49d8-bde9-b976a267c2ba",
   "metadata": {},
   "source": [
    "### First row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18641788-8698-49cb-998f-fdc672f43410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 : [[8]\n",
      " [8]]\n",
      "W1 : [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1 : [[0.]\n",
      " [0.]]\n",
      "--------------------------------------------------\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "**************************************************\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "W2 : [[0.1]\n",
      " [0.1]]\n",
      "b2 : [[0.]]\n",
      "--------------------------------------------------\n",
      "A2 : [[0.54150519]]\n",
      "**************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tHere A0 is [8, 8](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Loss 0.613402628898913\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[0,:-1].values.reshape(2, 1)\n",
    "Y = df.iloc[0,-1]\n",
    "\n",
    "network_structure = [2, 2, 1]\n",
    "\n",
    "params = initialize_params(network_structure)\n",
    "y_hat, A_prev = forward_propagation(X, params)\n",
    "y_hat = y_hat[0][0]\n",
    "update_parameters(params, Y, y_hat, A_prev, X)\n",
    "print(f\"\\n\\n-----------------------------------------------------------------------------------------\")\n",
    "print(f\"|\\tHere A0 is [8, 8](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\\t|\")\n",
    "print(f\"-----------------------------------------------------------------------------------------\\n\\n\")\n",
    "print(f\"Loss {-Y * np.log(y_hat) - (1 - Y) * np.log(1 - y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1df53fdd-8ebe-4d90-988d-79f357b8f692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.10000513, 0.1       ],\n",
       "        [0.10000513, 0.10000513]]),\n",
       " 'b1': array([[6.41054186e-07],\n",
       "        [6.41054186e-07]]),\n",
       " 'W2': array([[0.10003815],\n",
       "        [0.10003815]]),\n",
       " 'b2': array([[0.100084]])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84acd7-6a0e-4361-b1fb-9ed428e09e5a",
   "metadata": {},
   "source": [
    "### Second data-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3c88537-2e3e-4b3d-981c-795c1c343379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 : [[7]\n",
      " [9]]\n",
      "W1 : [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1 : [[0.]\n",
      " [0.]]\n",
      "--------------------------------------------------\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "**************************************************\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "W2 : [[0.1]\n",
      " [0.1]]\n",
      "b2 : [[0.]]\n",
      "--------------------------------------------------\n",
      "A2 : [[0.54150519]]\n",
      "**************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tHere A0 is [7, 9](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Loss 0.613402628898913\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[1,:-1].values.reshape(2, 1)\n",
    "Y = df.iloc[1,-1]\n",
    "\n",
    "network_structure = [2, 2, 1]\n",
    "\n",
    "params = initialize_params(network_structure)\n",
    "y_hat, A_prev = forward_propagation(X, params)\n",
    "y_hat = y_hat[0][0]\n",
    "update_parameters(params, Y, y_hat, A_prev, X)\n",
    "print(f\"\\n\\n-----------------------------------------------------------------------------------------\")\n",
    "print(f\"|\\tHere A0 is [7, 9](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\\t|\")\n",
    "print(f\"-----------------------------------------------------------------------------------------\\n\\n\")\n",
    "print(f\"Loss {-Y * np.log(y_hat) - (1 - Y) * np.log(1 - y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc48aa5e-d5e7-48f1-af74-1b77f7d90e10",
   "metadata": {},
   "source": [
    "### Third data-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e24a03b6-3e88-4cf5-b572-f2c38382a9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 : [[ 6]\n",
      " [10]]\n",
      "W1 : [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1 : [[0.]\n",
      " [0.]]\n",
      "--------------------------------------------------\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "**************************************************\n",
      "A1 : [[0.83201839]\n",
      " [0.83201839]]\n",
      "W2 : [[0.1]\n",
      " [0.1]]\n",
      "b2 : [[0.]]\n",
      "--------------------------------------------------\n",
      "A2 : [[0.54150519]]\n",
      "**************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tHere A0 is [6, 10](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Loss 0.7798063059256977\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[2,:-1].values.reshape(2, 1)\n",
    "Y = df.iloc[2,-1]\n",
    "\n",
    "network_structure = [2, 2, 1]\n",
    "\n",
    "params = initialize_params(network_structure)\n",
    "y_hat, A_prev = forward_propagation(X, params)\n",
    "y_hat = y_hat[0][0]\n",
    "update_parameters(params, Y, y_hat, A_prev, X)\n",
    "print(f\"\\n\\n-----------------------------------------------------------------------------------------\")\n",
    "print(f\"|\\tHere A0 is [6, 10](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\\t|\")\n",
    "print(f\"-----------------------------------------------------------------------------------------\\n\\n\")\n",
    "print(f\"Loss {-Y * np.log(y_hat) - (1 - Y) * np.log(1 - y_hat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fda840-858e-428e-a389-61cb7d73fc26",
   "metadata": {},
   "source": [
    "### Fourth data-point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f46d0bc-ffa3-4eee-8cc2-355889886a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 : [[5]\n",
      " [5]]\n",
      "W1 : [[0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "b1 : [[0.]\n",
      " [0.]]\n",
      "--------------------------------------------------\n",
      "A1 : [[0.73105858]\n",
      " [0.73105858]]\n",
      "**************************************************\n",
      "A1 : [[0.73105858]\n",
      " [0.73105858]]\n",
      "W2 : [[0.1]\n",
      " [0.1]]\n",
      "b2 : [[0.]]\n",
      "--------------------------------------------------\n",
      "A2 : [[0.53648795]]\n",
      "**************************************************\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------\n",
      "|\tHere A0 is [5, 5](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\t|\n",
      "-----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Loss 0.768922894759937\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[3,:-1].values.reshape(2, 1)\n",
    "Y = df.iloc[3,-1]\n",
    "\n",
    "network_structure = [2, 2, 1]\n",
    "\n",
    "params = initialize_params(network_structure)\n",
    "y_hat, A_prev = forward_propagation(X, params)\n",
    "y_hat = y_hat[0][0]\n",
    "update_parameters(params, Y, y_hat, A_prev, X)\n",
    "print(f\"\\n\\n-----------------------------------------------------------------------------------------\")\n",
    "print(f\"|\\tHere A0 is [5, 5](cgpa, profile_score), A1 is [O11, O12], A2 is [O21](y_hat)\\t|\")\n",
    "print(f\"-----------------------------------------------------------------------------------------\\n\\n\")\n",
    "print(f\"Loss {-Y * np.log(y_hat) - (1 - Y) * np.log(1 - y_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d516a05-2516-442d-ba87-081308267941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, params):\n",
    "    A = X\n",
    "    L = len(params) // 2\n",
    "\n",
    "    for l in range(1, L + 1):\n",
    "        A_prev = A\n",
    "        Wl = params['W' + str(l)]\n",
    "        bl = params['b' + str(l)]\n",
    "\n",
    "        A = forward(A_prev, Wl, bl)\n",
    "\n",
    "    return A, A_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c782ca9-c756-477d-85a8-4cc7c2ef5c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At 1 epoch, loss = 0.5846636507416068\n",
      "At 2 epoch, loss = 0.5440218915708116\n",
      "At 3 epoch, loss = 0.5283082977874415\n",
      "At 4 epoch, loss = 0.5131404516232378\n",
      "At 5 epoch, loss = 0.49849705343666784\n",
      "At 6 epoch, loss = 0.48435962245363395\n",
      "At 7 epoch, loss = 0.47071140574746606\n",
      "At 8 epoch, loss = 0.45753696372037356\n",
      "At 9 epoch, loss = 0.44482183038729606\n",
      "At 10 epoch, loss = 0.4325522425029809\n",
      "At 11 epoch, loss = 0.42071493028919477\n",
      "At 12 epoch, loss = 0.40929696181128955\n",
      "At 13 epoch, loss = 0.39828563285310514\n",
      "At 14 epoch, loss = 0.3876683943460917\n",
      "At 15 epoch, loss = 0.3774328099181526\n",
      "At 16 epoch, loss = 0.3675665368405723\n",
      "At 17 epoch, loss = 0.3580573244796984\n",
      "At 18 epoch, loss = 0.3488930252312734\n",
      "At 19 epoch, loss = 0.3400616137737159\n",
      "At 20 epoch, loss = 0.3315512112825512\n",
      "At 21 epoch, loss = 0.3233501119763046\n",
      "At 22 epoch, loss = 0.3154468100009793\n",
      "At 23 epoch, loss = 0.3078300252014601\n",
      "At 24 epoch, loss = 0.30048872677605953\n",
      "At 25 epoch, loss = 0.2934121541716655\n",
      "At 26 epoch, loss = 0.2865898348607372\n",
      "At 27 epoch, loss = 0.280011598858154\n",
      "At 28 epoch, loss = 0.27366758999617913\n",
      "At 29 epoch, loss = 0.2675482740896225\n",
      "At 30 epoch, loss = 0.2616444441998116\n",
      "At 31 epoch, loss = 0.25594722325321595\n",
      "At 32 epoch, loss = 0.2504480642954114\n",
      "At 33 epoch, loss = 0.24513874866916405\n",
      "At 34 epoch, loss = 0.2400113824014572\n",
      "At 35 epoch, loss = 0.23505839107195617\n",
      "At 36 epoch, loss = 0.23027251341761013\n",
      "At 37 epoch, loss = 0.22564679390706732\n",
      "At 38 epoch, loss = 0.2211745744959595\n",
      "At 39 epoch, loss = 0.21684948575114643\n",
      "At 40 epoch, loss = 0.21266543750951786\n",
      "At 41 epoch, loss = 0.2086166092155407\n",
      "At 42 epoch, loss = 0.20469744006176294\n",
      "At 43 epoch, loss = 0.20090261903814313\n",
      "At 44 epoch, loss = 0.19722707497947634\n",
      "At 45 epoch, loss = 0.1936659666853228\n",
      "At 46 epoch, loss = 0.19021467317366528\n",
      "At 47 epoch, loss = 0.18686878411794686\n",
      "At 48 epoch, loss = 0.18362409050704118\n",
      "At 49 epoch, loss = 0.18047657555898128\n",
      "At 50 epoch, loss = 0.1774224059117674\n",
      "At 51 epoch, loss = 0.1744579231081766\n",
      "At 52 epoch, loss = 0.1715796353860832\n",
      "At 53 epoch, loss = 0.16878420978124242\n",
      "At 54 epoch, loss = 0.16606846454569815\n",
      "At 55 epoch, loss = 0.16342936188183743\n",
      "At 56 epoch, loss = 0.16086400098955433\n",
      "At 57 epoch, loss = 0.15836961142190686\n",
      "At 58 epoch, loss = 0.15594354674300842\n",
      "At 59 epoch, loss = 0.15358327848059672\n",
      "At 60 epoch, loss = 0.15128639036474256\n",
      "At 61 epoch, loss = 0.14905057284342632\n",
      "At 62 epoch, loss = 0.14687361786520614\n",
      "At 63 epoch, loss = 0.14475341391885607\n",
      "At 64 epoch, loss = 0.1426879413196832\n",
      "At 65 epoch, loss = 0.1406752677321605\n",
      "At 66 epoch, loss = 0.13871354391855711\n",
      "At 67 epoch, loss = 0.13680099970336762\n",
      "At 68 epoch, loss = 0.13493594014352123\n",
      "At 69 epoch, loss = 0.133116741894593\n",
      "At 70 epoch, loss = 0.13134184976350474\n",
      "At 71 epoch, loss = 0.12960977343851188\n",
      "At 72 epoch, loss = 0.12791908438758792\n",
      "At 73 epoch, loss = 0.12626841291666074\n",
      "At 74 epoch, loss = 0.12465644537949273\n",
      "At 75 epoch, loss = 0.12308192153134917\n",
      "At 76 epoch, loss = 0.12154363201894453\n",
      "At 77 epoch, loss = 0.1200404159994993\n",
      "At 78 epoch, loss = 0.11857115888208047\n",
      "At 79 epoch, loss = 0.11713479018472966\n",
      "At 80 epoch, loss = 0.1157302815012003\n",
      "At 81 epoch, loss = 0.1143566445714448\n",
      "At 82 epoch, loss = 0.11301292945028543\n",
      "At 83 epoch, loss = 0.11169822276899813\n",
      "At 84 epoch, loss = 0.11041164608481144\n",
      "At 85 epoch, loss = 0.10915235431359385\n",
      "At 86 epoch, loss = 0.10791953424125084\n",
      "At 87 epoch, loss = 0.10671240310960023\n",
      "At 88 epoch, loss = 0.10553020727272264\n",
      "At 89 epoch, loss = 0.10437222092000098\n",
      "At 90 epoch, loss = 0.10323774486227791\n",
      "At 91 epoch, loss = 0.10212610537774805\n",
      "At 92 epoch, loss = 0.10103665311439725\n",
      "At 93 epoch, loss = 0.0999687620459743\n",
      "At 94 epoch, loss = 0.09892182847864701\n",
      "At 95 epoch, loss = 0.09789527010565766\n",
      "At 96 epoch, loss = 0.09688852510743771\n",
      "At 97 epoch, loss = 0.09590105129478611\n",
      "At 98 epoch, loss = 0.09493232529284812\n",
      "At 99 epoch, loss = 0.09398184176375785\n",
      "At 100 epoch, loss = 0.09304911266592678\n"
     ]
    }
   ],
   "source": [
    "params = initialize_params(network_structure)\n",
    "epochs = 100\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    loss = []\n",
    "    \n",
    "    for j in range(X.shape[0]):\n",
    "        \n",
    "        X = df.iloc[j,:-1].values.reshape(2, 1)\n",
    "        Y = df.iloc[j,-1]\n",
    "\n",
    "        y_hat, A_previous = forward_prop(X, params)\n",
    "        y_hat = y_hat[0][0]\n",
    "\n",
    "        update_parameters(params, Y, y_hat, A_previous, X)\n",
    "\n",
    "        loss.append((-Y * np.log(y_hat) - (1 - Y) * np.log(1 - y_hat)))\n",
    "\n",
    "    print(f\"At {i + 1} epoch, loss = {np.array(loss).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe8571-0cc0-42c5-b088-b1aab1b537f0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "<h2 style=\"text-align: center;\">Using Keras</h2>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cbc4b929-3c3a-4159-bbc4-0a013366790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d14f8423-9bda-4ad7-a388-96c2fe7b1897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Parth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid', input_dim=2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d9dbaaf1-403d-431c-a4a9-6e4d584e0c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m6\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m3\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a34abac-371a-47ae-87e3-63b7ff2d2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As above shows, keras has initialized weights in his own way, but we want to initialize weights in our own way\n",
    "new_weights = [np.array([[0.1, 0.1], \n",
    "                         [0.1, 0.1]], dtype=np.float32),\n",
    "              np.array([0., 0.], dtype=np.float32),\n",
    "              np.array([[0.1],\n",
    "                        [0.1]], dtype=np.float32),\n",
    "              np.array([0.], dtype=np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1a0f6be-6870-462a-ab6d-cd3422e460d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8227941-15d6-43d4-890b-0b3dcedbbcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.1, 0.1],\n",
       "        [0.1, 0.1]], dtype=float32),\n",
       " array([0., 0.], dtype=float32),\n",
       " array([[0.1],\n",
       "        [0.1]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f52b5a52-76d6-4152-9770-7ca51cb4bc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(learning_rate=0.1)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "083f0283-e82b-4905-9802-3dfcfb353001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.6798\n",
      "Epoch 2/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4132\n",
      "Epoch 3/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5500\n",
      "Epoch 4/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5659\n",
      "Epoch 5/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5843\n",
      "Epoch 6/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5227\n",
      "Epoch 7/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4978\n",
      "Epoch 8/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5919\n",
      "Epoch 9/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5677\n",
      "Epoch 10/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4849\n",
      "Epoch 11/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4734\n",
      "Epoch 12/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4736\n",
      "Epoch 13/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4933\n",
      "Epoch 14/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4498\n",
      "Epoch 15/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3513\n",
      "Epoch 16/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5033\n",
      "Epoch 17/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5203\n",
      "Epoch 18/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4405\n",
      "Epoch 19/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4586\n",
      "Epoch 20/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4259\n",
      "Epoch 21/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4886\n",
      "Epoch 22/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4773\n",
      "Epoch 23/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.3698\n",
      "Epoch 24/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.4606\n",
      "Epoch 25/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5699\n",
      "Epoch 26/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5788\n",
      "Epoch 27/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.5319\n",
      "Epoch 28/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3570\n",
      "Epoch 29/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.4385\n",
      "Epoch 30/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3212\n",
      "Epoch 31/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.4361\n",
      "Epoch 32/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3637\n",
      "Epoch 33/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3412\n",
      "Epoch 34/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.4496 \n",
      "Epoch 35/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6423\n",
      "Epoch 36/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3673\n",
      "Epoch 37/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.4719\n",
      "Epoch 38/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3698\n",
      "Epoch 39/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4818\n",
      "Epoch 40/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2885\n",
      "Epoch 41/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3268\n",
      "Epoch 42/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.4210\n",
      "Epoch 43/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3206\n",
      "Epoch 44/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3530\n",
      "Epoch 45/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2911\n",
      "Epoch 46/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2462\n",
      "Epoch 47/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3539\n",
      "Epoch 48/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4859\n",
      "Epoch 49/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3416\n",
      "Epoch 50/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.3866\n",
      "Epoch 51/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2749\n",
      "Epoch 52/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2374\n",
      "Epoch 53/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3406\n",
      "Epoch 54/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4051\n",
      "Epoch 55/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2851\n",
      "Epoch 56/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3129\n",
      "Epoch 57/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1737\n",
      "Epoch 58/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.2747\n",
      "Epoch 59/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1922\n",
      "Epoch 60/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.3308\n",
      "Epoch 61/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.2419\n",
      "Epoch 62/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2494\n",
      "Epoch 63/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4176 \n",
      "Epoch 64/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2876\n",
      "Epoch 65/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2498\n",
      "Epoch 66/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1714\n",
      "Epoch 67/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1331\n",
      "Epoch 68/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.2344\n",
      "Epoch 69/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2391\n",
      "Epoch 70/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1635\n",
      "Epoch 71/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1830\n",
      "Epoch 72/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2345\n",
      "Epoch 73/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1960\n",
      "Epoch 74/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1960\n",
      "Epoch 75/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1609\n",
      "Epoch 76/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1831\n",
      "Epoch 77/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2201\n",
      "Epoch 78/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1663\n",
      "Epoch 79/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.1433 \n",
      "Epoch 80/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1089 \n",
      "Epoch 81/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2250\n",
      "Epoch 82/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1179\n",
      "Epoch 83/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2935\n",
      "Epoch 84/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1672\n",
      "Epoch 85/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1727\n",
      "Epoch 86/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1694\n",
      "Epoch 87/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.1711\n",
      "Epoch 88/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1339 \n",
      "Epoch 89/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1243\n",
      "Epoch 90/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1026\n",
      "Epoch 91/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1220\n",
      "Epoch 92/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1642\n",
      "Epoch 93/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1287\n",
      "Epoch 94/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1239\n",
      "Epoch 95/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0843\n",
      "Epoch 96/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1479\n",
      "Epoch 97/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1211\n",
      "Epoch 98/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1943\n",
      "Epoch 99/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0785\n",
      "Epoch 100/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1019\n",
      "Epoch 101/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0716\n",
      "Epoch 102/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1092\n",
      "Epoch 103/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1220\n",
      "Epoch 104/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0776\n",
      "Epoch 105/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0997\n",
      "Epoch 106/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0894\n",
      "Epoch 107/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0806\n",
      "Epoch 108/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1275\n",
      "Epoch 109/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0857\n",
      "Epoch 110/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0670\n",
      "Epoch 111/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0971\n",
      "Epoch 112/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0917\n",
      "Epoch 113/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0705\n",
      "Epoch 114/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0788\n",
      "Epoch 115/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0533\n",
      "Epoch 116/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0859\n",
      "Epoch 117/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0971\n",
      "Epoch 118/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0531\n",
      "Epoch 119/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0585\n",
      "Epoch 120/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0887\n",
      "Epoch 121/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0678\n",
      "Epoch 122/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0462\n",
      "Epoch 123/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0918\n",
      "Epoch 124/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0606\n",
      "Epoch 125/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0864\n",
      "Epoch 126/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0865\n",
      "Epoch 127/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0748\n",
      "Epoch 128/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0610\n",
      "Epoch 129/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1094\n",
      "Epoch 130/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0508\n",
      "Epoch 131/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0450\n",
      "Epoch 132/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2007 \n",
      "Epoch 133/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0718\n",
      "Epoch 134/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0828\n",
      "Epoch 135/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1156\n",
      "Epoch 136/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1411\n",
      "Epoch 137/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0578\n",
      "Epoch 138/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0345\n",
      "Epoch 139/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0676\n",
      "Epoch 140/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0443\n",
      "Epoch 141/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0506\n",
      "Epoch 142/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0386\n",
      "Epoch 143/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0704\n",
      "Epoch 144/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0428\n",
      "Epoch 145/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0481 \n",
      "Epoch 146/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0489\n",
      "Epoch 147/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0595\n",
      "Epoch 148/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0561\n",
      "Epoch 149/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0307\n",
      "Epoch 150/150\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x18f081cd510>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df.iloc[:,:-1].values, df['placed'].values, epochs=150, verbose=1, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34e5211-b36c-4f8f-864f-cf85c89f9d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (tfenv)",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
